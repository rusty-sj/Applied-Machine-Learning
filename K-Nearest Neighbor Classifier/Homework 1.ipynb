{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 99\t train_err 17.88% (+:19.50%)\tdev error 15.70% (+:19.10%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "def load_data_into_map(path):\n",
    "    return list(map(lambda s: s.strip().split(\", \"), open(path).readlines()))        #Get comma separated rows from training input\n",
    "\n",
    "age_normalizer = 50      #Interpreted from training data \n",
    "\n",
    "def form_mappings_from_training(data_map):\n",
    "    mappings = {} \n",
    "    for row in data_map:\n",
    "        for index, val in enumerate(row):\n",
    "            feature = (index, val)            #Feature e.g., (1, 'Self-emp-not-inc')\n",
    "            if index not in [0, 7, 9]:        #Parse only categorical fields, skip age, hours-per-week and target\n",
    "                if feature not in mappings:\n",
    "                    mappings[feature] = len(mappings)        #(1, 'Self-emp-not-inc'): Serial feature #\n",
    "    return mappings\n",
    "\n",
    "def binarize_normalize_data(data_map, mappings):\n",
    "    partial_binarized = []\n",
    "    given_targets = []\n",
    "    total_rows = 0\n",
    "    for row in data_map:\n",
    "        person_row = []\n",
    "        for index, val in enumerate(row):\n",
    "            if index not in [0, 7, 9]:\n",
    "                feature = (index, val)\n",
    "                if feature in mappings:\n",
    "                    person_row.append(mappings[feature])\n",
    "                else:\n",
    "                    mappings[feature] = len(mappings)\n",
    "            elif index in [0, 7]:\n",
    "                person_row.append(float(val) / age_normalizer)\n",
    "            elif index == 9:\n",
    "                given_targets.append(val)\n",
    "        partial_binarized.append(person_row)\n",
    "        total_rows += 1\n",
    "        \n",
    "    binarized_vector = np.zeros((total_rows, len(mappings) + 2))\n",
    "    for index, person_row in enumerate(partial_binarized):\n",
    "        for i, val in enumerate(person_row):\n",
    "            if i not in [0, 7]:\n",
    "                binarized_vector[index][val] = 1\n",
    "            elif i == 0:\n",
    "                binarized_vector[index][-2] = val\n",
    "            elif i == 7:\n",
    "                binarized_vector[index][-1] = val             \n",
    "    return binarized_vector, given_targets, total_rows\n",
    "\n",
    "\n",
    "def binarize_all_data(data_map, mappings):\n",
    "    partial_binarized = []\n",
    "    given_targets = []\n",
    "    total_rows = 0\n",
    "    for row in data_map:\n",
    "        person_row = []\n",
    "        for index, val in enumerate(row):\n",
    "            if index != 9:\n",
    "                feature = (index, val)\n",
    "                if feature in mappings:\n",
    "                    person_row.append(mappings[feature])\n",
    "                else:\n",
    "                    mappings[feature] = len(mappings)\n",
    "            else:\n",
    "                given_targets.append(val)\n",
    "        partial_binarized.append(person_row)\n",
    "        total_rows += 1\n",
    "        \n",
    "    binarized_vector = np.zeros((total_rows, len(mappings)))\n",
    "    for index, person_row in enumerate(partial_binarized):\n",
    "        for i, val in enumerate(person_row):\n",
    "            binarized_vector[index][val] = 1         \n",
    "    return binarized_vector, given_targets, total_rows\n",
    "\n",
    "def find_topk(k, manh_or_eucl, vector_train, vector_dev):\n",
    "    diff = vector_train - vector_dev[:, np.newaxis]\n",
    "    if manh_or_eucl == \"eucl\":\n",
    "        dist = np.linalg.norm(diff, axis = 2)\n",
    "    elif manh_or_eucl == \"manh\":\n",
    "        dist = np.sum(np.abs(diff), axis = 2)\n",
    "    train_rows = vector_train.shape[0]\n",
    "    kVals = range(k) if k < train_rows else range(train_rows)\n",
    "    top_k_indices = np.argpartition(dist, kVals, axis = 1)[:, :k] \n",
    "    top_k_dist = dist[np.arange(dist.shape[0])[:, None], top_k_indices]\n",
    "    return top_k_indices, top_k_dist\n",
    "\n",
    "def knn(k, manh_or_eucl, vector_train, vector_dev, train_targets):\n",
    "    top_k_indices, top_k_dist = find_topk(k, manh_or_eucl, vector_train, vector_dev)\n",
    "    predicted_list = []\n",
    "    for row in top_k_indices:\n",
    "        nearby_targets = []\n",
    "        for index in row:\n",
    "            nearby_targets.append(train_targets[index])\n",
    "        predicted_list.append(max(set(nearby_targets), key=nearby_targets.count))\n",
    "    return predicted_list \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_map_train = load_data_into_map(\"hw1-data/income.train.txt.5k\")\n",
    "    mappings = form_mappings_from_training(data_map_train)\n",
    "    vector_train, train_targets, train_rows = binarize_normalize_data(data_map_train, mappings)\n",
    "    \n",
    "    data_map_dev = load_data_into_map(\"hw1-data/income.dev.txt\")\n",
    "    vector_dev, dev_targets, dev_rows = binarize_normalize_data(data_map_dev, mappings)\n",
    "    \n",
    "    if vector_train.shape[1] != vector_dev.shape[1]:\n",
    "        for i in range(vector_dev.shape[1] - vector_train.shape[1]):\n",
    "            vector_train = np.insert(vector_train, i - 2, values=0, axis=1)\n",
    "        \n",
    "   \n",
    "    '''data_map_test = load_data_into_map(\"hw1-data/income.test.blind\")\n",
    "    vector_test, test_targets, test_rows = binarize_normalize_data(data_map_test, mappings)\n",
    "    \n",
    "    if vector_train.shape[1] != vector_test.shape[1]:\n",
    "        vector_train = np.insert(vector_train, -2, values=0, axis=1)\n",
    "    \n",
    "    predicted_list = knn(41, \"eucl\", vector_train, vector_test, train_targets)\n",
    "    \n",
    "    test_positivity = 0\n",
    "    #shutil.copy(\"hw1-data/income.test.blind\", \"hw1-data/income.test.predicted\") \n",
    "                \n",
    "    with open('hw1-data/income.test.blind', 'r') as istr:\n",
    "        with open('hw1-data/income.test.predicted', 'w') as ostr:\n",
    "            for i, line in enumerate(istr):\n",
    "                line = line.rstrip('\\n')\n",
    "                line = line + ', ' + predicted_list[i]\n",
    "                print(line, file=ostr)\n",
    "                if predicted_list[i] == '>50K':\n",
    "                    test_positivity += 1\n",
    "    print(test_positivity / test_rows * 100)'''\n",
    "    \n",
    "    #ks = [1, 3, 5, 7, 9, 99, 999, 9999]\n",
    "    ks = [99]\n",
    "    for k in ks:\n",
    "        predicted_list = knn(k, \"eucl\", vector_train, vector_dev, train_targets)\n",
    "        dev_positivity = 0\n",
    "        dev_errors = 0\n",
    "        for idx, val in enumerate(predicted_list):\n",
    "            if val == \">50K\":\n",
    "                dev_positivity += 1\n",
    "            if val != dev_targets[idx]:\n",
    "                dev_errors += 1\n",
    "        dev_positivity = dev_positivity / dev_rows * 100\n",
    "        dev_errors = dev_errors / dev_rows * 100\n",
    "        \n",
    "        predicted_list_2 = knn(k, \"eucl\", vector_train, vector_train, train_targets)\n",
    "        train_positivity = 0\n",
    "        train_errors = 0\n",
    "        for idx, val in enumerate(predicted_list_2):\n",
    "            if val == \">50K\":\n",
    "                train_positivity += 1\n",
    "            if val != train_targets[idx]:\n",
    "                train_errors += 1\n",
    "        train_positivity = train_positivity / train_rows * 100\n",
    "        train_errors = train_errors / train_rows * 100\n",
    "        print(\"k = %d\\t train_err %.2f%% (+:%.2f%%)\\tdev error %.2f%% (+:%.2f%%)\" % (k, train_errors, train_positivity, dev_errors, dev_positivity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
